Code Review 2024-01-30

Notes on addressing idem-lab github repo admin
How to manage admin-level across the whole group
While protecting "private" state of certain repos, e.g., BDSS

Code review of JEV work for Dave
Overview
1st part Lucy transmission intensity
2nd  part Dave wildlife reservoir part
Current workflow
Loads all functions in R/
In root are all the scripts for steps
It would help us to see a sketch of workflow
Some of the goals/intent with code review
Intent is to try and make the code more repeatable and replicable and future use
Concern is wide scope
Consolidating the code relevant to the manuscript
Supplied one-off un-bootstrapped outputs to government, but now need to prep man
Not sure if replicable
Meta problem – of how to get organised
One goal is to fund the work in the project into spatial transmission risk analyses
applicable to JEV, … other diseases that circulate with vectors and hosts
Aiming for a pipeline targets approach for this kind of spatial transmission risk
Thoughts on systematic naming of files / managing the garden of forking paths that happens when doing a data analysis
Gerry tried having a systematic approach and felt there were mixed results:
https://github.com/geryan/rfst/tree/master/R
Perhaps discuss how to better name functions/process
See Jenny Bryan’s notes on this: https://www.tidyverse.org/blog/2017/12/workflow-vs-script/
Discussion around using git branches to manage data analysis decisions
Discussion of keeping everything in a targets workflow
Other comments
.rds/ data outputs should be stored in specific outputs/data folders, not at root directory
.RHistory file should be removed - check global options to remove this. This contains a keystroke history of everything run in an R session and can get quite big
documentation for functions has been really useful - documentation at the top of the R script
https://github.com/milesmcbain/fnmate can help automate functions
Discussions 
Dave walked through the workflow of how the JEV process worked, using a cool sharing of his remarkable tablet
Can we take the concepts that come up and put them into a “training” list of things to do, and maybe we can use this in hacky hour or something?



from, targets::use_targets()

```
  # For distributed computing in tar_make(), supply a {crew} controller
  # as discussed at https://books.ropensci.org/targets/crew.html.
  # Choose a controller that suits your needs. For example, the following
  # sets a controller with 2 workers which will run as local R processes:
  #
  #   controller = crew::crew_controller_local(workers = 2)
  #
  # Alternatively, if you want workers to run on a high-performance computing
  # cluster, select a controller from the {crew.cluster} package. The following
  # example is a controller for Sun Grid Engine (SGE).
  # 
  #   controller = crew.cluster::crew_controller_sge(
  #     workers = 50,
  #     # Many clusters install R as an environment module, and you can load it
  #     # with the script_lines argument. To select a specific verison of R,
  #     # you may need to include a version string, e.g. "module load R/4.3.0".
  #     # Check with your system administrator if you are unsure.
  #     script_lines = "module load R"
  #   )

```

Plan for next code review session

- Dave could walk through JEV project and turning it into a targets pipeline
- Working on creating a pipeline for tasks that might come up in the next iteration of this, or writing a script that describes the overall running of this

Future sessions / things to learn
- Demonstrating/perfecting/improving targets workflow
- How to make good use of git branches
idea of git flow
- “orthogonality” - how to set up each branch to do just one thing
- How to use targets with SLURM / HPC




